{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Name :** Harshita<br>\n",
        "**Roll No:** 102317003<br>\n",
        "**Subgroup:** 3Q11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja8e2pNrwYm9"
      },
      "source": [
        "Q1. Q1. Write a Python program to scrape all available books from the website \n",
        "(https://books.toscrape.com/) Books to Scrape – a live site built for practicing scraping (safe, \n",
        "legal, no anti-bot). For each book, extract the following details: \n",
        "1. Title \n",
        "2. Price \n",
        "3. Availability (In stock / Out of stock) \n",
        "4. Star Rating (One, Two, Three, Four, Five) \n",
        "Store the scraped results into a Pandas DataFrame and export them to a CSV file named \n",
        "books.csv. \n",
        "(Note: Use the requests library to fetch the HTML page. Use BeautifulSoup to parse and extract \n",
        "book details and handle pagination so that books from all pages are scraped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR3V9U3TwPRP",
        "outputId": "b254490f-2c92-4789-f34f-f7c2ac379071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page 1 done...\n",
            "Page 2 done...\n",
            "Page 3 done...\n",
            "Page 4 done...\n",
            "Page 5 done...\n",
            "Page 6 done...\n",
            "Page 7 done...\n",
            "Page 8 done...\n",
            "Page 9 done...\n",
            "Page 10 done...\n",
            "Page 11 done...\n",
            "Page 12 done...\n",
            "Page 13 done...\n",
            "Page 14 done...\n",
            "Page 15 done...\n",
            "Page 16 done...\n",
            "Page 17 done...\n",
            "Page 18 done...\n",
            "Page 19 done...\n",
            "Page 20 done...\n",
            "Page 21 done...\n",
            "Page 22 done...\n",
            "Page 23 done...\n",
            "Page 24 done...\n",
            "Page 25 done...\n",
            "Page 26 done...\n",
            "Page 27 done...\n",
            "Page 28 done...\n",
            "Page 29 done...\n",
            "Page 30 done...\n",
            "Page 31 done...\n",
            "Page 32 done...\n",
            "Page 33 done...\n",
            "Page 34 done...\n",
            "Page 35 done...\n",
            "Page 36 done...\n",
            "Page 37 done...\n",
            "Page 38 done...\n",
            "Page 39 done...\n",
            "Page 40 done...\n",
            "Page 41 done...\n",
            "Page 42 done...\n",
            "Page 43 done...\n",
            "Page 44 done...\n",
            "Page 45 done...\n",
            "Page 46 done...\n",
            "Page 47 done...\n",
            "Page 48 done...\n",
            "Page 49 done...\n",
            "Page 50 done...\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
        "\n",
        "books_data = []\n",
        "\n",
        "page = 1\n",
        "while True:\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        break\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    books = soup.find_all('article', class_='product_pod')\n",
        "\n",
        "    for book in books:\n",
        "        title = book.h3.a['title']\n",
        "        price = book.find('p', class_='price_color').text\n",
        "        availability = book.find('p', class_='instock availability').text.strip()\n",
        "        star_rating = book.p['class'][1]\n",
        "\n",
        "        books_data.append({\n",
        "            'Title': title,\n",
        "            'Price': price,\n",
        "            'Availability': availability,\n",
        "            'Star Rating': star_rating\n",
        "        })\n",
        "\n",
        "    print(f\"Page {page} done...\")\n",
        "    page += 1\n",
        "\n",
        "df = pd.DataFrame(books_data)\n",
        "\n",
        "df.to_csv('books.csv', index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rea8XK5Gw-LC"
      },
      "source": [
        "Q2. Q2. Write a Python program to scrape the IMDB Top 250 Movies list \n",
        "(https://www.imdb.com/chart/top/) . For each movie, extract the following details: \n",
        "1. Rank (1–250) \n",
        "2. Movie Title \n",
        "3. Year of Release \n",
        "4. IMDB Rating \n",
        "Store the results in a Pandas DataFrame and export it to a CSV file named imdb_top250.csv. \n",
        "(Note: Use Selenium/Playwright to scrape the required details from this website) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xACg97ow5tR",
        "outputId": "7bfccce6-d99a-40c9-e454-4fcf8faa80a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "   Position                        Movie Release Year Rating\n",
            "0         1  1. The Shawshank Redemption         1994    9.3\n",
            "1         2             2. The Godfather         1972    9.2\n",
            "2         3           3. The Dark Knight         2008    9.1\n",
            "3         4     4. The Godfather Part II         1974    9.0\n",
            "4         5              5. 12 Angry Men         1957    9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "\n",
        "chrome_opts = Options()\n",
        "chrome_opts.add_argument(\"--headless\")\n",
        "chrome_opts.add_argument(\"--no-sandbox\")\n",
        "chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "chrome_opts.add_argument(\n",
        "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "    \"Chrome/115.0.0.0 Safari/537.36\"\n",
        ")\n",
        "\n",
        "browser = webdriver.Chrome(options=chrome_opts)\n",
        "\n",
        "browser.get(\"https://www.imdb.com/chart/top/\")\n",
        "time.sleep(5)\n",
        "\n",
        "film_list = []\n",
        "movie_cards = browser.find_elements(By.CSS_SELECTOR, \".ipc-metadata-list-summary-item\")\n",
        "\n",
        "for rank, card in enumerate(movie_cards, start=1):\n",
        "    try:\n",
        "        name = card.find_element(By.CSS_SELECTOR, \"h3\").text\n",
        "        release_year = card.find_element(By.CSS_SELECTOR, \".cli-title-metadata-item\").text\n",
        "        score = card.find_element(By.CSS_SELECTOR, \".ipc-rating-star--imdb\").text.split()[0]\n",
        "        film_list.append([rank, name, release_year, score])\n",
        "    except Exception as e:\n",
        "        print(f\"skipping due to error: {e}\")\n",
        "\n",
        "browser.quit()\n",
        "\n",
        "imdb_table = pd.DataFrame(film_list, columns=[\"Position\", \"Movie\", \"Release Year\", \"Rating\"])\n",
        "imdb_table.to_csv(\"imdb_top250.csv\", index=False)\n",
        "print(imdb_table.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OwT7ExUxN-6"
      },
      "source": [
        "Q3. Q3. Write a Python program to scrape the weather information for top world cities from the \n",
        "given website (https://www.timeanddate.com/weather/) . For each city, extract the following \n",
        "details: \n",
        "1. City Name \n",
        "2. Temperature \n",
        "3. Weather Condition (e.g., Clear, Cloudy, Rainy, etc.) \n",
        "Store the results in a Pandas DataFrame and export it to a CSV file named weather.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyxur-fNxFna",
        "outputId": "ec551f79-d6e2-4b4a-99f3-cae3cf6c3bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "                           City_Name              Condition Temperature\n",
            "0                  Albania, Tirana *           Sunny. Mild.       73 °F\n",
            "1                   Algeria, Algiers           Sunny. Mild.       74 °F\n",
            "2                     Angola, Luanda             Fog. Mild.       70 °F\n",
            "3  Antigua and Barbuda, Saint John's  Passing clouds. Warm.       81 °F\n",
            "4            Argentina, Buenos Aires           Clear. Cool.       57 °F\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "\n",
        "chrome_opts = Options()\n",
        "chrome_opts.add_argument(\"--headless\")\n",
        "chrome_opts.add_argument(\"--no-sandbox\")\n",
        "chrome_opts.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "chrome_opts.add_argument(\n",
        "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "    \"Chrome/115.0.0.0 Safari/537.36\"\n",
        ")\n",
        "\n",
        "browser = webdriver.Chrome(options=chrome_opts)\n",
        "\n",
        "browser.get(\"https://www.timeanddate.com/weather/?sort=1&low=4\")\n",
        "time.sleep(5)\n",
        "\n",
        "weather_list = []\n",
        "weather_rows = browser.find_elements(By.CSS_SELECTOR, \"table.zebra.fw.tb-theme tbody tr\")\n",
        "\n",
        "for row in weather_rows:\n",
        "    try:\n",
        "        city_name = row.find_element(By.CSS_SELECTOR, \"td:nth-child(1)\").text\n",
        "        cond_td = row.find_element(By.CSS_SELECTOR, \"td:nth-child(3)\")\n",
        "        condition_img = cond_td.find_element(By.TAG_NAME, \"img\")\n",
        "        condition = condition_img.get_attribute(\"title\")\n",
        "        temperature = row.find_element(By.CSS_SELECTOR, \"td:nth-child(4)\").text\n",
        "        weather_list.append([city_name, condition, temperature])\n",
        "    except Exception as e:\n",
        "        print(f\"skipping due to error: {e}\")\n",
        "\n",
        "browser.quit()\n",
        "\n",
        "weather = pd.DataFrame(weather_list, columns=[\"City_Name\", \"Condition\", \"Temperature\"])\n",
        "weather.to_csv(\"weather.csv\", index=False)\n",
        "print(weather.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TompTUUbxhg8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
